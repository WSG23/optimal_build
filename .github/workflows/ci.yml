name: CI

on:
  push:
    branches:
      - main
  pull_request:

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  lint:
    name: Lint & Format
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements-dev.txt

      - name: Install lint dependencies
        run: |
          pip install -r backend/requirements-dev.txt

      - name: Run pre-commit hooks
        run: pre-commit run --all-files --show-diff-on-failure

  db_upgrade_smoke:
    name: DB Upgrade Smoke
    runs-on: ubuntu-latest
    needs: lint
    env:
      POSTGRES_SERVER: 127.0.0.1
      POSTGRES_DB: building_compliance
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_PORT: '5432'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt

      - name: Install backend runtime dependencies
        run: |
          pip install -r backend/requirements.txt

      - name: Start Postgres service
        run: |
          docker compose -f docker-compose.yml up -d postgres

      - name: Wait for Postgres
        run: |
          set -euo pipefail
          for attempt in $(seq 1 30); do
            if docker compose -f docker-compose.yml exec -T postgres pg_isready -U "$POSTGRES_USER"; then
              exit 0
            fi
            sleep 2
          done
          echo "Postgres did not become ready in time" >&2
          exit 1

      - name: Run Alembic migrations
        run: make db.upgrade

      - name: Stop Postgres service
        if: always()
        run: |
          docker compose -f docker-compose.yml down --volumes

  backend:
    name: Backend Smokes & Tests
    runs-on: ubuntu-latest
    needs:
      - lint
      - db_upgrade_smoke
    env:
      POSTGRES_SERVER: 127.0.0.1
      POSTGRES_DB: building_compliance
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_PORT: '5432'
      REDIS_URL: redis://127.0.0.1:6379
      CELERY_BROKER_URL: redis://127.0.0.1:6379/0
      CELERY_RESULT_BACKEND: redis://127.0.0.1:6379/1
      RQ_REDIS_URL: redis://127.0.0.1:6379/2
      S3_ENDPOINT: http://127.0.0.1:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      IMPORTS_BUCKET_NAME: cad-imports
      EXPORTS_BUCKET_NAME: cad-exports
      PYTHONPATH: backend
      CI_ARTIFACTS: ${{ github.workspace }}/artifacts
      REFERENCE_STORAGE: ${{ github.workspace }}/artifacts/reference_storage
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements-dev.txt

      - name: Install backend dependencies
        run: |
          pip install -r backend/requirements-dev.txt

      - name: Start backing services
        run: |
          docker compose -f docker-compose.yml up -d postgres redis minio

      - name: Wait for services
        run: |
          set -euo pipefail
          postgres_ready=false
          for attempt in $(seq 1 30); do
            if docker compose -f docker-compose.yml exec -T postgres pg_isready -U "$POSTGRES_USER"; then
              postgres_ready=true
              break
            fi
            sleep 2
          done
          if [ "$postgres_ready" != "true" ]; then
            echo "Postgres did not become ready in time" >&2
            exit 1
          fi
          docker compose -f docker-compose.yml exec -T redis redis-cli ping
          minio_ready=false
          for attempt in $(seq 1 30); do
            if curl -sSf http://127.0.0.1:9000/minio/health/live > /dev/null; then
              minio_ready=true
              break
            fi
            sleep 2
          done
          if [ "$minio_ready" != "true" ]; then
            echo "Minio did not become ready in time" >&2
            exit 1
          fi

      - name: Prepare smoke artifacts
        run: |
          mkdir -p "$CI_ARTIFACTS"
          mkdir -p "$REFERENCE_STORAGE"

      - name: Run database migrations
        run: make db.upgrade

      - name: Seed reference data
        run: make seed-data

      - name: Seed non-regulatory datasets
        run: |
          if make -n seed-nonreg >/dev/null 2>&1; then
            make seed-nonreg
          else
            echo "seed-nonreg target not present; skipping"
          fi

      - name: Run watch_fetch ingestion smoke
        run: |
          python -m backend.flows.watch_fetch \
            --once \
            --offline \
            --storage-path "$REFERENCE_STORAGE" \
            --summary-path "$CI_ARTIFACTS/watch_fetch_summary.json"

      - name: Run parse_segment ingestion smoke
        run: |
          python -m backend.flows.parse_segment \
            --once \
            --storage-path "$REFERENCE_STORAGE" \
            --summary-path "$CI_ARTIFACTS/parse_segment_summary.json" \
            --min-documents 1 \
            --min-clauses 1

      - name: Verify ingestion artifacts
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          artifacts = Path(os.environ["CI_ARTIFACTS"])
          watch_summary = json.loads((artifacts / "watch_fetch_summary.json").read_text())
          if watch_summary.get("document_count", 0) <= 0:
              raise SystemExit("watch_fetch ingestion produced no documents")

          parse_summary = json.loads((artifacts / "parse_segment_summary.json").read_text())
          if parse_summary.get("clause_count", 0) <= 0:
              raise SystemExit("parse_segment ingestion produced no clauses")
          PY

      - name: Launch backend API for smokes
        run: |
          python -m uvicorn app.main:app \
            --host 0.0.0.0 \
            --port 8000 \
            --log-level warning &
          echo $! > "$RUNNER_TEMP/backend-e2e.pid"
        working-directory: backend

      - name: Wait for backend readiness
        run: |
          set -euo pipefail
          for attempt in $(seq 1 40); do
            if curl -sSf http://127.0.0.1:8000/health > /dev/null; then
              exit 0
            fi
            sleep 2
          done
          echo "Backend API did not become ready in time" >&2
          exit 1

      - name: Run buildable screening smoke
        run: |
          set -euo pipefail
          payload='{"address":"123 Example Ave","typ_floor_to_floor_m":3.4,"efficiency_ratio":0.8}'
          curl -sSf -X POST http://127.0.0.1:8000/api/v1/screen/buildable \
            -H 'content-type: application/json' \
            -d "$payload" \
            -o "$CI_ARTIFACTS/buildable_response.json"
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          artifacts = Path(os.environ["CI_ARTIFACTS"])
          data = json.loads((artifacts / "buildable_response.json").read_text())
          metrics = data.get("metrics") or {}
          if "zone_code" not in data:
              raise SystemExit("zone_code missing from buildable response")
          if "gfa_cap_m2" not in metrics:
              raise SystemExit("gfa_cap_m2 missing from buildable metrics")
          PY

      - name: Fetch OpenAPI schema
        run: |
          curl -sSf http://127.0.0.1:8000/openapi.json -o "$CI_ARTIFACTS/openapi.json"

      - name: Stop backend API
        if: always()
        run: |
          if [ -f "$RUNNER_TEMP/backend-e2e.pid" ]; then
            PID=$(cat "$RUNNER_TEMP/backend-e2e.pid")
            if ps -p "$PID" > /dev/null 2>&1; then
              kill "$PID"
              for attempt in $(seq 1 15); do
                if ps -p "$PID" > /dev/null 2>&1; then
                  sleep 1
                else
                  break
                fi
              done
              if ps -p "$PID" > /dev/null 2>&1; then
                kill -9 "$PID" || true
              fi
            fi
            rm -f "$RUNNER_TEMP/backend-e2e.pid"
          fi

      - name: Run backend tests
        run: |
          cd backend
          pytest -q --maxfail=1 --cov=app --cov-report=xml \
            tests/test_api/test_rules.py \
            tests/test_flows/test_watch_fetch_flow.py \
            tests/test_flows/test_parse_segment_flow.py \
            ../tests/finance/test_finance_smoke.py \
            tests/pwp/test_buildable_latency.py \
            tests/pwp/test_buildable_metrics.py

      - name: Collect coverage artifact
        run: |
          mkdir -p "$CI_ARTIFACTS"
          if [ -f backend/coverage.xml ]; then
            cp backend/coverage.xml "$CI_ARTIFACTS/backend-coverage.xml"
          fi

      - name: Stop services
        if: always()
        run: docker compose -f docker-compose.yml down --volumes

      - name: Upload backend artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-artifacts
          path: artifacts
          if-no-files-found: warn

  frontend-e2e:
    name: Frontend E2E
    runs-on: ubuntu-latest
    needs: backend
    env:
      POSTGRES_SERVER: 127.0.0.1
      POSTGRES_DB: building_compliance
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_PORT: '5432'
      REDIS_URL: redis://127.0.0.1:6379
      CELERY_BROKER_URL: redis://127.0.0.1:6379/0
      CELERY_RESULT_BACKEND: redis://127.0.0.1:6379/1
      RQ_REDIS_URL: redis://127.0.0.1:6379/2
      S3_ENDPOINT: http://127.0.0.1:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      IMPORTS_BUCKET_NAME: cad-imports
      EXPORTS_BUCKET_NAME: cad-exports
      PYTHONPATH: backend
      VITE_API_BASE_URL: http://127.0.0.1:8000/
      CI: 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: frontend/pnpm-lock.yaml

      - name: Enable Corepack
        run: corepack enable

      - name: Resolve pnpm store path
        id: pnpm-store
        run: echo "store-path=$(pnpm store path)" >> "$GITHUB_OUTPUT"

      - name: Cache pnpm store
        uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-store.outputs.store-path }}
          key: pnpm-${{ runner.os }}-${{ hashFiles('frontend/pnpm-lock.yaml', 'frontend/package.json') }}
          restore-keys: |
            pnpm-${{ runner.os }}-

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements-dev.txt

      - name: Install backend dependencies
        run: |
          pip install -r backend/requirements-dev.txt

      - name: Start backing services
        run: |
          docker compose -f docker-compose.yml up -d postgres redis minio

      - name: Wait for services
        run: |
          set -euo pipefail
          postgres_ready=false
          for attempt in $(seq 1 30); do
            if docker compose -f docker-compose.yml exec -T postgres pg_isready -U "$POSTGRES_USER"; then
              postgres_ready=true
              break
            fi
            sleep 2
          done
          if [ "$postgres_ready" != "true" ]; then
            echo "Postgres did not become ready in time" >&2
            exit 1
          fi
          docker compose -f docker-compose.yml exec -T redis redis-cli ping
          minio_ready=false
          for attempt in $(seq 1 30); do
            if curl -sSf http://127.0.0.1:9000/minio/health/live > /dev/null; then
              minio_ready=true
              break
            fi
            sleep 2
          done
          if [ "$minio_ready" != "true" ]; then
            echo "Minio did not become ready in time" >&2
            exit 1
          fi

      - name: Run database migrations
        run: make db.upgrade

      - name: Seed reference data
        run: make seed-data

      - name: Seed non-regulatory datasets
        run: |
          if make -n seed-nonreg >/dev/null 2>&1; then
            make seed-nonreg
          else
            echo "seed-nonreg target not present; skipping"
          fi

      - name: Install frontend dependencies
        run: pnpm -C frontend install --frozen-lockfile

      - name: Lint frontend application
        run: pnpm -C frontend lint

      - name: Run frontend unit tests
        run: pnpm -C frontend test

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('frontend/pnpm-lock.yaml', 'frontend/package.json') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install Playwright browsers
        run: pnpm -C frontend exec playwright install --with-deps

      - name: Launch backend API for E2E
        run: |
          python -m uvicorn app.main:app \
            --host 0.0.0.0 \
            --port 8000 \
            --log-level warning &
          echo $! > "$RUNNER_TEMP/backend-e2e.pid"
        working-directory: backend

      - name: Wait for backend readiness
        run: |
          set -euo pipefail
          for attempt in $(seq 1 40); do
            if curl -sSf http://127.0.0.1:8000/health > /dev/null; then
              exit 0
            fi
            sleep 2
          done
          echo "Backend API did not become ready in time" >&2
          exit 1

      - name: Run frontend end-to-end tests
        env:
          PLAYWRIGHT_SKIP_BROWSER_INSTALL: '1'
        run: pnpm -C frontend test:e2e

      - name: Stop backend API
        if: always()
        run: |
          if [ -f "$RUNNER_TEMP/backend-e2e.pid" ]; then
            PID=$(cat "$RUNNER_TEMP/backend-e2e.pid")
            if ps -p "$PID" > /dev/null 2>&1; then
              kill "$PID"
              for attempt in $(seq 1 15); do
                if ps -p "$PID" > /dev/null 2>&1; then
                  sleep 1
                else
                  break
                fi
              done
              if ps -p "$PID" > /dev/null 2>&1; then
                kill -9 "$PID" || true
              fi
            fi
            rm -f "$RUNNER_TEMP/backend-e2e.pid"
          fi

      - name: Stop services
        if: always()
        run: docker compose -f docker-compose.yml down --volumes

      - name: Upload Playwright artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-playwright
          path: |
            frontend/test-results
            frontend/playwright-report
          if-no-files-found: warn
